{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T04:20:51.673422Z",
     "start_time": "2018-08-06T04:20:51.660574Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "#from attributegetter import *\n",
    "from generatengrams import ngrammatch\n",
    "from Contexts import *\n",
    "import json\n",
    "from Intents import *\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tflearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Phrases\n",
    "import logging\n",
    "\n",
    "#use the existing google bin to get word2vec representation\n",
    "#create own word 2 vec\n",
    "#perform word2vec on these words\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 6           # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "isUseZeros = True\n",
    "isUseOnes = False\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../../Datasets/GoogleNews-vectors-negative300.bin', binary=True, limit=500000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "#stemmer = LancasterStemmer()\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "#print(stopwords)\n",
    "only_alnum = re.compile(r\"[^\\w]+\") ## \\w => unicode alphabet\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(only_alnum, \" \", sentence).strip()\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the intent file\n",
    "import json\n",
    "intents = []\n",
    "files = os.listdir('./intents/')\n",
    "intents = {}\n",
    "documents = []\n",
    "\n",
    "def convertClassToNumber(intent):\n",
    "    if intent == 'BookRestaurant':\n",
    "        return 1\n",
    "    elif intent == 'movieChoice':\n",
    "        return 0\n",
    "    return -1\n",
    "\n",
    "def convertNumberToClass(intentNumber):\n",
    "    if intentNumber == 1:\n",
    "        return 'BookRestaurant'\n",
    "    elif intentNumber == 0:\n",
    "        return 'movieChoice'\n",
    "    return None\n",
    "\n",
    "for fil in files:\n",
    "    lines = open('./intents/'+fil, encoding='windows-1252').readlines()\n",
    "    intent_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.lower()\n",
    "        words = clean_sentence(line)\n",
    "        intent_lines.append(words)\n",
    "        documents.append((convertClassToNumber(fil[:-4]), words))\n",
    "    intents[fil[:-4]] = intent_lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_sentence2vec(documents, isUseZeros, isUseOnes):\n",
    "    missing_word_vecs={}\n",
    "    number_of_docs = len(documents)\n",
    "    word2vec_rep = np.zeros((number_of_docs, num_features))\n",
    "    count = 0 \n",
    "    labels = []\n",
    "    i=0\n",
    "    for document in documents:\n",
    "        tag = document[0]\n",
    "        doc_words = document[1]\n",
    "        #print(doc_words)\n",
    "        for word in doc_words: \n",
    "            try:\n",
    "                word2vec_rep[i]+=model[word]\n",
    "            except:\n",
    "                '''The word isn't in our pretrained word-vectors, hence we add a random gaussian noise\n",
    "                    to account for this. We store the random vector we assigned to the word, and reuse \n",
    "                    the same vector during test time to ensure consistency.'''\n",
    "                if word  not in missing_word_vecs.keys():\n",
    "                    if isUseZeros:\n",
    "                        missing_word_vecs[word] = np.zeros((num_features))\n",
    "                    elif isUseOnes:\n",
    "                        missing_word_vecs[word] = np.ones((num_features))\n",
    "                    else:\n",
    "                        missing_word_vecs[word] = np.random.normal(-0.25, 0.25, num_features)\n",
    "                word2vec_rep[i]+=missing_word_vecs[word]\n",
    "                count +=1\n",
    "        labels.append(tag)\n",
    "        i+=1\n",
    "    return word2vec_rep, labels, missing_word_vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word2vec_representation(doc_words):\n",
    "    word2vec_rep = np.zeros((1, num_features))\n",
    "    for word in doc_words: \n",
    "        try:\n",
    "            word2vec_rep+=model[word]\n",
    "        except:\n",
    "            '''The word isn't in our pretrained word-vectors, hence we add a random gaussian noise\n",
    "                    to account for this. We store the random vector we assigned to the word, and reuse \n",
    "                    the same vector during test time to ensure consistency.'''\n",
    "            if word  not in missing_word_vecs.keys():\n",
    "                if isUseZeros:\n",
    "                    missing_word_vecs[word] = np.zeros((num_features))\n",
    "                elif isUseOnes:\n",
    "                    missing_word_vecs[word] = np.ones((num_features))\n",
    "                else:\n",
    "                    missing_word_vecs[word] = np.random.normal(-0.25, 0.25, num_features)\n",
    "            word2vec_rep+=missing_word_vecs[word]\n",
    "    return word2vec_rep\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent2vec_rep, labels, missing_word_vecs = convert_sentence2vec(documents, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classification problem\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "classifier.fit(sent2vec_rep, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_class(sentence):\n",
    "    w2v1 = word2vec_representation(clean_sentence(sentence))\n",
    "    return convertNumberToClass(int(classifier.predict(w2v1))),classifier.predict_proba(w2v1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviedataset = pd.read_csv('corpus/moviedata.csv')\n",
    "moviedataset = moviedataset.apply(lambda x: x.astype(str).str.lower())\n",
    "moviedataset[['size']] = moviedataset[['size']].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "restaurantDataset = pd.read_csv('corpus/restaurantBooking.csv')\n",
    "restaurantDataset = restaurantDataset.apply(lambda x: x.astype(str).str.lower())\n",
    "restaurantDataset[['size']] = restaurantDataset[['size']].apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T04:20:52.452207Z",
     "start_time": "2018-08-06T04:20:52.433325Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_actions(current_intent, attributes, context):\n",
    "    '''This function performs the action for the intent\n",
    "    as mentioned in the intent config file'''\n",
    "    '''Performs actions pertaining to current intent\n",
    "    for action in current_intent.actions:\n",
    "        if action.contexts_satisfied(active_contexts):\n",
    "            return perform_action()\n",
    "    '''\n",
    "\n",
    "    context = IntentComplete()\n",
    "    return 'action: ' + current_intent.action, context\n",
    "\n",
    "def check_required_params(current_intent, attributes, context, inferred_attributes):\n",
    "    '''Collects attributes pertaining to the current intent'''\n",
    "    #print(attributes)\n",
    "    all_attributes = copy.deepcopy(attributes)\n",
    "    inferred_attributes_copy = copy.deepcopy(inferred_attributes)\n",
    "    all_attributes.update(inferred_attributes_copy)\n",
    "    for para in current_intent.params:\n",
    "        #print(para.name)\n",
    "        if para.required:\n",
    "            if para.name not in all_attributes:\n",
    "                #Example of where the context is born, implemented in Contexts.py\n",
    "                if para.name=='mname':\n",
    "                    context = MovieName()\n",
    "                elif para.name == 'mlocation':\n",
    "                    context = MovieLocation()\n",
    "                elif para.name == 'language':\n",
    "                    context = Language()\n",
    "                elif para.name == 'genre':\n",
    "                    context = Genre()\n",
    "                elif para.name == 'actor':\n",
    "                    context = Actor()\n",
    "                elif para.name == 'theatre':\n",
    "                    context = Theatre()\n",
    "                elif para.name == 'time':\n",
    "                    context = Time()\n",
    "                elif para.name == 'date':\n",
    "                    context = Date()\n",
    "                elif para.name == 'numberOfPeople':\n",
    "                    context = NumberOfPeople()\n",
    "                elif para.name == 'seattype':\n",
    "                    context = SeatType()\n",
    "                \n",
    "                #returning a random prompt frmo available choices.\n",
    "                return random.choice(para.prompts), context\n",
    "\n",
    "    return None, context\n",
    "\n",
    "\n",
    "def input_processor(user_input, context, attributes, intent):\n",
    "    '''Spellcheck and entity extraction functions go here'''\n",
    "    \n",
    "    #user_input = TextBlob(user_input).correct().string\n",
    "    \n",
    "    #update the attributes, abstract over the entities in user input\n",
    "    attributes, cleaned_input = getattributes(user_input, context, attributes)\n",
    "    \n",
    "    return attributes, cleaned_input\n",
    "\n",
    "def loadIntent(path, intent):\n",
    "    with open(path) as fil:\n",
    "        dat = json.load(fil)\n",
    "        intent = dat[intent]\n",
    "        #print(intent)\n",
    "        return Intent(intent['intentname'],intent['Parameters'], intent['actions'])\n",
    "\n",
    "def intentIdentifier(clean_input, context,current_intent):\n",
    "    clean_input = clean_input.lower()\n",
    "    #print(clean_input)\n",
    "    #Scoring Algorithm, can be changed.\n",
    "    scores = ngrammatch(clean_input)\n",
    "    \n",
    "    #choosing here the intent with the highest score\n",
    "    scores = sorted_by_second = sorted(scores, key=lambda tup: tup[1])\n",
    "    intentclass, probabilities = predict_class(clean_input)\n",
    "    print(scores, intentclass, probabilities)\n",
    "    if(current_intent==None):\n",
    "        if(clean_input==\"movie\"):\n",
    "            return loadIntent('params/newparams.cfg', 'movieChoice')\n",
    "        elif(clean_input==\"restaurant\"):\n",
    "            return loadIntent('params/newparams.cfg', 'BookRestaurant')\n",
    "        else:\n",
    "            return loadIntent('params/newparams.cfg', intentclass)\n",
    "    else:\n",
    "        #If current intent is not none, stick with the ongoing intent\n",
    "        return current_intent\n",
    "\n",
    "def getattributes(uinput,context,attributes):\n",
    "    '''This function marks the entities in user input, and updates\n",
    "    the attributes dictionary'''\n",
    "    #Can use context to context specific attribute fetching\n",
    "    if context.name.startswith('IntentComplete'):\n",
    "        return attributes, uinput\n",
    "    else:\n",
    "        #Code can be optimised here, loading the same files each time suboptimal \n",
    "        files = os.listdir('./entities/')\n",
    "        entities = {}\n",
    "        for fil in files:\n",
    "            lines = open('./entities/'+fil, encoding='windows-1252').readlines()\n",
    "            for i, line in enumerate(lines):\n",
    "                line = line.lower()\n",
    "                lines[i] = line[:-1]\n",
    "            entities[fil[:-4]] = '|'.join(lines)\n",
    "\n",
    "        #Extract entity and update it in attributes dict\n",
    "        for entity in entities:\n",
    "            for i in entities[entity].split('|'):\n",
    "                if i.lower() in uinput.lower():\n",
    "                    attributes[entity] = i\n",
    "        for entity in entities:\n",
    "                uinput = re.sub(entities[entity],r'$'+entity,uinput,flags=re.IGNORECASE)\n",
    "\n",
    "        #Example of where the context is being used to do conditional branching.\n",
    "        #if 'mname' in attributes  or (context.name=='MovieBooking_moviename' and context.active):\n",
    "        #    match = attributes['mname']\n",
    "        #    context.active = False\n",
    "        return attributes,uinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T04:20:53.392144Z",
     "start_time": "2018-08-06T04:20:53.381302Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Session:\n",
    "    def __init__(self, attributes=None, active_contexts=[FirstGreeting(), IntentComplete() ]):\n",
    "        \n",
    "        '''Initialise a default session'''\n",
    "        \n",
    "        #Active contexts not used yet, can use it to have multiple contexts\n",
    "        self.active_contexts = active_contexts\n",
    "        \n",
    "        #Contexts are flags which control dialogue flow, see Contexts.py        \n",
    "        self.context = FirstGreeting()\n",
    "        \n",
    "        #Intent tracks the current state of dialogue\n",
    "        #self.current_intent = First_Greeting()\n",
    "        self.current_intent = None\n",
    "        \n",
    "        #attributes hold the information collected over the conversation\n",
    "        self.attributes = {}\n",
    "        self.inferred_attributes = {}\n",
    "        \n",
    "    def update_contexts(self):\n",
    "        '''Not used yet, but is intended to maintain active contexts'''\n",
    "        for context in self.active_contexts:\n",
    "            if context.active:\n",
    "                context.decrease_lifespan()\n",
    "\n",
    "    def reply(self, user_input):\n",
    "        '''Generate response to user input'''\n",
    "        \n",
    "        if 'bye' in user_input.lower() or 'thank' in user_input.lower() or 'quit' in user_input.lower() or 'awesome' in user_input.lower() :\n",
    "            self.attributes = {}\n",
    "            self.inferred_attributes = {}\n",
    "            self.context = FirstGreeting()\n",
    "            self.current_intent = None\n",
    "            return 'Thanks for chatting, hope you have a good day'\n",
    "        \n",
    "        self.attributes, clean_input = input_processor(user_input, self.context, self.attributes, self.current_intent)\n",
    "        self.current_intent = intentIdentifier(clean_input, self.context, self.current_intent)\n",
    "        \n",
    "        #constructing query to run on the data set\n",
    "        #print(self.attributes)\n",
    "        isDFEmpty = False\n",
    "        if self.attributes:\n",
    "            if self.current_intent.name =='movieChoice':\n",
    "                isDFEmpty, self.inferred_attributes,qry = add_unique_attributes(moviedataset, self.attributes)\n",
    "            elif self.current_intent.name =='BookRestaurant':\n",
    "                isDFEmpty, self.inferred_attributes,qry = add_unique_attributes(restaurantDataset, self.attributes)\n",
    "\n",
    "        if isDFEmpty == True and self.current_intent.name =='movieChoice':\n",
    "            prompt = 'No tickets available for '+ str(self.attributes) +'\\n\\n Please retry'\n",
    "            self.attributes = {} \n",
    "            self.inferred_attributes = {}\n",
    "            self.context = FirstGreeting()\n",
    "            self.current_intent = None\n",
    "            return prompt\n",
    "        if isDFEmpty == True and self.current_intent.name =='BookRestaurant':\n",
    "            prompt = 'No restaurant table available for '+ str(self.attributes) +'\\n\\n Please retry'\n",
    "            self.attributes = {}\n",
    "            self.inferred_attributes = {}\n",
    "            self.context = FirstGreeting()\n",
    "            self.current_intent = None\n",
    "            return prompt\n",
    "        prompt, self.context = check_required_params(self.current_intent, self.attributes, self.context, self.inferred_attributes)\n",
    "        #prompt being None means all parameters satisfied, perform the intent action\n",
    "        \n",
    "        if prompt is None:\n",
    "            if self.context.name!='IntentComplete':\n",
    "                prompt, self.context = check_actions(self.current_intent, self.attributes, self.context)\n",
    "                prompt = prompt + '\\n'+ str(self.attributes) + str(self.inferred_attributes) +'\\n\\n'+ 'Thank you'\n",
    "        \n",
    "        #Resets the state after the Intent is complete\n",
    "        if self.context.name=='IntentComplete':\n",
    "            self.attributes = {}\n",
    "            self.inferred_attributes = {}\n",
    "            self.context = FirstGreeting()\n",
    "            self.current_intent = None\n",
    "        elif self.context.name == 'MovieBooking_moviename':\n",
    "            prompt = prompt +  '\\n'+ str(moviedataset.query(qry)) \n",
    "        elif self.context.name == 'RestaurantBooking_restaurantNames':\n",
    "            prompt = prompt +  '\\n'+ str(restaurantDataset.query(qry)) \n",
    "\n",
    "            \n",
    "        \n",
    "        return prompt\n",
    "\n",
    "def add_unique_attributes(df, attributes):\n",
    "    if not attributes:\n",
    "        False, {}, ''\n",
    "    qry = ' and '.join([\"{} == '{}'\".format(k,v) for k,v in attributes.items() if k !='size' and k!='greeting'])\n",
    "    if 'size' in attributes:\n",
    "        if not qry:\n",
    "            qry = 'size >='+ convertToNumber(attributes['size'])\n",
    "        else:\n",
    "            qry = qry + ' and size >='+ convertToNumber(attributes['size'])\n",
    "    y = {}\n",
    "    #print(qry)\n",
    "    if not qry:\n",
    "        return False, y\n",
    "    subsetDF = df.query(qry)\n",
    "    print(subsetDF)\n",
    "    print('\\n\\n')\n",
    "    if subsetDF.empty:\n",
    "        return True, y,qry\n",
    "    \n",
    "    for col in subsetDF:\n",
    "        if col == 'numberOfPeople':\n",
    "            continue\n",
    "        unique_vals = subsetDF[col].unique()\n",
    "        if len(unique_vals) ==1 and col not in attributes:\n",
    "            y[col] = unique_vals[0]\n",
    "    return False, y,qry\n",
    "\n",
    "def convertToNumber(numberword):\n",
    "    if numberword =='one':\n",
    "        return '1'\n",
    "    elif numberword == 'two':\n",
    "        return '2'\n",
    "    elif numberword == 'three':\n",
    "        return '3'\n",
    "    elif numberword == 'four':\n",
    "        return '4'\n",
    "    elif numberword == 'five':\n",
    "        return '5'\n",
    "    elif numberword == 'six':\n",
    "        return '6'\n",
    "    elif numberword == 'seven':\n",
    "        return '7'\n",
    "    elif numberword == 'eight':\n",
    "        return '8'\n",
    "    elif numberword == 'nine':\n",
    "        return '9'\n",
    "    elif numberword == 'ten':\n",
    "        return '10'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T04:20:58.656549Z",
     "start_time": "2018-08-06T04:20:54.129029Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session = Session()\n",
    "\n",
    "print ('BOT: Hi! How may I assist you?')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    inp = input('User: ')\n",
    "    print ('BOT:', session.reply(inp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
